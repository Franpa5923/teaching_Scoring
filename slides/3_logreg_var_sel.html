<!DOCTYPE html>
<html lang="en"><head>
<script src="3_logreg_var_sel_files/libs/clipboard/clipboard.min.js"></script>
<script src="3_logreg_var_sel_files/libs/quarto-html/tabby.min.js"></script>
<script src="3_logreg_var_sel_files/libs/quarto-html/popper.min.js"></script>
<script src="3_logreg_var_sel_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="3_logreg_var_sel_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="3_logreg_var_sel_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="3_logreg_var_sel_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="3_logreg_var_sel_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Louis Olive">
  <meta name="dcterms.date" content="2025-10-01">
  <title>The Logistic Regression model - Model selection and assessment</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="3_logreg_var_sel_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="3_logreg_var_sel_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="3_logreg_var_sel_files/libs/revealjs/dist/theme/quarto.css">
  <link href="3_logreg_var_sel_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="3_logreg_var_sel_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="3_logreg_var_sel_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="3_logreg_var_sel_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">The Logistic Regression model - Model selection and assessment</h1>
  <p class="subtitle">M2 D3S/EGR 2025-2026</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Louis Olive 
</div>
<div class="quarto-title-author-email">
<a href="mailto:louis.olive@gmail.com / louis.olive@ut-capitole.fr">louis.olive@gmail.com / louis.olive@ut-capitole.fr</a>
</div>
</div>
</div>

  <p class="date">October 1, 2025</p>
</section>
<section>
<section id="outline" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>Outline</h1>
<!-- Quick and dirty -->
<!-- Lightbox Figures not working with Revealjs / https://quarto.org/docs/output-formats/html-lightbox-figures.html -->
<!-- https://stackoverflow.com/questions/56361986/zoom-function-in-rmarkdown-html-plot/59401761#59401761 -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js" "=""></script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
</script>
<style>
.algo {
  font-family: monospace;
  background: #f8f8f8;        /* light gray background */
  padding: 1em 1.25em;        /* inner spacing */
  border-radius: 10px;        /* rounded corners */
  box-shadow: 2px 2px 6px rgba(0,0,0,0.1); /* subtle shadow */
  line-height: 1.4;           /* spacing between lines */
}
</style>
</section>
<section id="outline-1" class="slide level2">
<h2>Outline</h2>
<div class="extrapad">
<ul>
<li>Model selection</li>
<li>Model assessment</li>
<li>A short intro to Decision Trees</li>
</ul>
</div>
</section></section>
<section>
<section id="model-selection" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>Model selection</h1>

</section>
<section id="model-selection-1" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="disclaimer">Disclaimer</h3>
<p>This is a very short introduction to model selection in the context of Logisitc Regression.</p>
<p>For a better coverage, chapter 7 <code>Model Assessment and Selection</code> of <span class="citation" data-cites="hastie2009">Hastie et al. (<a href="#/references" role="doc-biblioref" onclick="">2009</a>)</span> discusses in depth the interplay between bias, variance and model complexity, in a general setting. Chapter 6 <code>Linear Model Selection and Regularization</code> of <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span> discusses methods to automatically perform variable selection in the context of linear models.</p>
<p>Also more developed in the Practical part of the Course.</p>
</section>
<section id="model-selection-2" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="manual-selection---the-old-way">Manual selection - the old way</h3>
<p>Usually a combination of:</p>
<ul>
<li><p>Single-variable analysis/screening: keep predictors showing individual association with the response</p></li>
<li><p>Correlation analysis: remove redundant predictors that are highly correlated</p></li>
</ul>
<p>see for example <a href="https://mingze-gao.com/posts/credit-risk-modelling/#credit-scoring---estimating-pd">this excellent blog post</a></p>
<p>Very similar to Exploratory Data Analysis.</p>
</section>
<section id="model-selection-3" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="best-subset-selection">Best subset selection</h3>
<p>The “best subset” method evaluates all possible combinations of predictor variables, resulting in <span class="math inline">\(2^p-1\)</span> models for p predictors, and selects the one that optimizes a specified criterion, such as the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">Akaike Information Criterion</a> (AIC) or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">Bayesian Information Criterion</a> (BIC). It is computationally intensive and usually restricted to low dimension data sets:</p>
<div class="algo">
<p><span class="math display">\[
\begin{aligned}
&amp;1.\ \text{For } k = 1, \ldots, p: \\
&amp;\quad (a)\ \text{Fit all } {p \choose k} \text{ models with exactly $k$ predictors} \\
&amp;\quad (b)\ \text{Pick the best among them and call it } \mathcal{M}_k \\
&amp;\quad\quad \text{(largest log-likelihood or min deviance for Logistic Regression)} \\
\\
&amp;2.\ \text{Select the single best model from } \mathcal{M}_1, \ldots, \mathcal{M}_p \\
&amp;\quad \text{using a chosen criterion (validation error, AIC, BIC, ...)}
\end{aligned}
\]</span></p>
</div>
</section>
<section id="model-selection-4" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="best-subset---aic-bic">Best subset - AIC / BIC</h3>
<p>Given <span class="math inline">\(|\mathcal M|\)</span> we define the two following criteria which represent two way of penalizing the log-likelihood <span class="math inline">\(\ell(Y,\hat\beta)\)</span>:</p>
<p><span class="math display">\[
\textrm{AIC}(\mathcal M)=-2\ell(Y,\hat\beta)+2|\mathcal M|
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\textrm{BIC}(\mathcal M)=-2\ell(Y,\hat\beta)+|\mathcal M|\log(n)
\]</span></p>
</section>
<section id="model-selection-5" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="best-subset---with-r">Best subset - with R</h3>
<p>The package <code>bestglm</code> allows best subset selection up to roughly <span class="math inline">\(15\)</span> variables, by default it uses BIC. We use the Default data set to illustrate because Agriculture Farm Lending has around <span class="math inline">\(30\)</span> variables:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>BIC
BICq equivalent for q in (0.000417890560228229, 0.989405669357382)
Best Model:
                 Estimate  Std. Error    z value      Pr(&gt;|z|)
(Intercept) -10.749495878 0.369191361 -29.116326 2.230782e-186
studentYes   -0.714877620 0.147519010  -4.846003  1.259734e-06
balance       0.005738104 0.000231847  24.749526 3.136911e-135</code></pre>
</div>
</div>
</section>
<section id="model-selection-6" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="stepwise-logistic-regression-forward-selection">Stepwise Logistic Regression : Forward selection</h3>
<p>Stepwise methods (Forward or Backward) iteratively add or remove variables based on a chosen criterion; once a variable is selected or dropped, it is fixed, and the process carries on, making them less computationally intensive than Best Subset selection. Below the Forward selection method:</p>
<div class="algo">
<p><span class="math display">\[
\begin{aligned}
&amp;1.\ \text{For } k = 1, \ldots, p: \\
&amp;\quad (a)\ \text{Consider all } p+1-k \text{ models that augment the predictors in } \mathcal{M}_k \\
&amp;\quad\quad \text{ with one additional predictor} \\
&amp;\quad (b)\ \text{Pick the best among these } p+1-k \text{ models and call it } \mathcal{M}_{k+1} \\
&amp;\quad\quad \text{(largest log-likelihood or min deviance for Logistic Regression)} \\
\\
&amp;2.\ \text{Select the single best model from } \mathcal{M}_1, \ldots, \mathcal{M}_p \\
&amp;\quad \text{using a chosen criterion (validation error, AIC, BIC, ...)}
\end{aligned}
\]</span></p>
</div>
<!-- ------------------------------------------------------------------------ -->
<!-- **Algorithm**: Forward stepwise selection -->
<!-- ------------------------------------------------------------------------ -->
<!-- 1.  For $k=1,\cdots,p$: -->
<!--     (a) Consider all $p+1-k$ models that augment the predictors in $\mathcal M_k$ with one additional predictor. -->
<!--     (b) Pick the best among these $p+1-k$ models, and call it $\mathcal M_{k+1}$. In the case of Logistic Regression, best usually means largest log-likelihood or min deviance. -->
<!-- 2.  Select a single best model from among $\mathcal M_1,\cdots,\mathcal M_p$ using a criterion. Usually the prediction error on a validation set, AIC, BIC... -->
<!-- ------------------------------------------------------------------------ -->
</section>
<section id="model-selection-7" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="stepwise-logistic-regression-backward-selection">Stepwise Logistic Regression : Backward selection</h3>
<p>Below the Backward selection method:</p>
<div class="algo">
<p><span class="math display">\[
\begin{aligned}
&amp;1.\ \text{Let } \mathcal{M}_p \text{ denote the full model containing all $p$ predictors} \\
\\
&amp;2.\ \text{For } k = p, \ldots, 1: \\
&amp;\quad (a)\ \text{Consider all $k$ models that contain all but one of the predictors in } \mathcal{M}_k \text{ (total of $k-1$ predictors)} \\
&amp;\quad (b)\ \text{Pick the best among these $k$ models and call it } \mathcal{M}_{k-1} \\
&amp;\quad\quad \text{(largest log-likelihood or min deviance} \\
&amp;\quad\quad \text{for Logistic Regression)} \\
\\
&amp;3.\ \text{Select a single best model from } \mathcal{M}_1, \ldots, \mathcal{M}_p \\
&amp;\quad \text{using a chosen criterion (validation error, AIC, BIC, ...)}
\end{aligned}
\]</span></p>
</div>
<!-- ------------------------------------------------------------------------ -->
<!-- **Algorithm**: Backward stepwise selection -->
<!-- ------------------------------------------------------------------------ -->
<!-- 1.  Let $\mathcal M_p$ denote the full model, which contains all $p$ predictors. -->
<!-- 2.  For $k=p,\cdots,1$: -->
<!--     (a) Consider all $k$ models that contain all but one of the predictors in $\mathcal M_k$, for a total of $k-1$ predictors. -->
<!--     (b) Pick the best among these $k$ models, and call it $\mathcal M_{k-1}$. In the case of Logistic Regression, best usually means largest log-likelihood or min deviance. -->
<!-- 3.  Select a single best model from among $\mathcal M_1,\cdots,\mathcal M_p$ using a criterion. Usually the prediction error on a validation set, AIC, BIC... -->
<!-- ------------------------------------------------------------------------ -->
<p>Additionally versions mixing forward and backward stepwise selection exist.</p>
</section>
<section id="model-selection-8" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="penalized-logistic-regression">Penalized Logistic Regression</h3>
<p>As an alternative, penalized regression techniques:</p>
<ul>
<li>fit a Logistic Regression model with all <span class="math inline">\(p\)</span> predictors but introducing constraints/penalization on coefficients (ie shrink coefficients toward zero)</li>
<li>turns out to be an efficient means of variance reduction and/or variable selection</li>
</ul>
<p>To estimate Logistic Regression model, we maximized in <span class="math inline">\(\beta\)</span> the log-likelihood:</p>
<p><span class="math display">\[
\ell(Y,\beta)=\log L(Y,\beta) =\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right)
\]</span></p>
<p>In the context of penalized Logistic Regression the idea is to minimize in <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
-\ell(Y,\beta)+\lambda_2\lVert\beta\rVert_2 + \lambda_1\lVert\beta\rVert_1
\]</span> where <span class="math inline">\(\lambda_1, \lambda_2\)</span> are two constants.</p>
</section>
<section id="model-selection-9" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="penalized-logistic-regression-1">Penalized Logistic Regression</h3>
<p>Having set <span class="math inline">\(\lambda_1, \lambda_2\)</span>, minimize in <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
-\ell(Y,\beta)+\lambda_2\lVert\beta\rVert_2 + \lambda_1\lVert\beta\rVert_1
\]</span></p>
<p><span class="math inline">\(\lambda_1&gt;0, \lambda_2=0\)</span>: Lasso penalty. Promotes sparsity, selects some predictors while shrinking others to zero.</p>
<p><span class="math inline">\(\lambda_1=0, \lambda_2&gt;0\)</span>: Ridge penalty.</p>
<p><span class="math inline">\(\lambda_1&gt;0, \lambda_2&gt;0\)</span>: Elastic Net penalty.</p>
</section>
<section id="model-selection-10" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="penalized-logistic-regression-2">Penalized Logistic Regression</h3>
<p>Usually the following graphs are given in textbooks/slides to give some intuition about Ridge/Lasso:</p>

<img data-src="../images/lasso_classic_graph.png" width="350" class="r-stretch quarto-figure-center"><p>The figure below is taken from the original Lasso article by Tibshirani published in 1996. Without entering to much details, Ridge does a proportional shrinkage of all coefficients while Lasso tends to truncates some of the coefficients at zero.</p>
</section>
<section id="model-selection-11" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="penalized-logistic-regression-3">Penalized Logistic Regression</h3>
<p>Re-using here the 2D Mixture data set from introduction slides to give further intuition about Ridge/Lasso penalties:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-12" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="ridge">Ridge</h3>
<p>Ridge estimator is:</p>
<p><span class="math display">\[
\hat \beta_{ridge}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)+\lambda\lVert\beta\rVert_2
\]</span></p>
<p>equivalently:</p>
<p><span class="math display">\[
\hat \beta_{ridge}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)
\]</span></p>
<p>subject to <span class="math inline">\(\lVert\beta\rVert_2 \leq t\)</span>, where <span class="math inline">\(t\)</span> maps to <span class="math inline">\(\lambda\)</span> (the higher <span class="math inline">\(\lambda\)</span>, the lower <span class="math inline">\(t\)</span>).</p>
</section>
<section id="model-selection-13" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="ridge-1">Ridge</h3>
<p>Log-likelihood of the Logistic Regression (colored levels lines centered around the MLE) for the Mixture data set, adding the Ridge constraint (the circle in black is the boundary <span class="math inline">\(\lVert\beta\rVert_2 \leq t\)</span>) :</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-5-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-14" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="ridge---with-r">Ridge - with R</h3>
<p>In R the package <code>glmnet</code> implements the Lasso, Ridge and Elastic Net penalties in particular for Logistic Regression. Ridge Logistic Regression coefficients for <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> as a function of <span class="math inline">\(\lambda\)</span>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="fu">library</span>(glmnetUtils) <span class="co"># convenient package allowing to use R formulas instead of glmnet sparse matrix</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co"># Fitting Logistic Regression model with Ridge (alpha=0) penalty. Small lambda.min.ratio so that penalty is almost zero at start.</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>mixture_ridge <span class="ot">&lt;-</span> glmnetUtils<span class="sc">::</span><span class="fu">glmnet</span>(Y <span class="sc">~</span> ., <span class="at">data=</span>data_mixture_example, <span class="at">family=</span><span class="st">"binomial"</span>, <span class="at">alpha=</span><span class="dv">0</span>, <span class="at">lambda.min.ratio=</span><span class="fl">0.000001</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co"># Extracting coefficients</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>ridge_result <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">as.matrix</span>(<span class="fu">cbind</span>(mixture_ridge<span class="sc">$</span>lambda, mixture_ridge<span class="sc">$</span>a0, <span class="fu">t</span>(mixture_ridge<span class="sc">$</span>beta))))</span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="fu">names</span>(ridge_result) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"lambda"</span>, <span class="st">"(Intercept)"</span>, <span class="fu">row.names</span>(mixture_ridge<span class="sc">$</span>beta))</span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co"># Showing results for very high/low values of lambda</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="fu">bind_rows</span>(ridge_result <span class="sc">%&gt;%</span> <span class="fu">head</span>(),ridge_result <span class="sc">%&gt;%</span> <span class="fu">tail</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 12 × 4
      lambda `(Intercept)`        x1       x2
       &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
 1 268.          -9.86e-32 -1.04e-37 2.64e-37
 2 233.          -5.00e- 4 -4.44e- 4 1.12e- 3
 3 202.          -5.75e- 4 -5.10e- 4 1.29e- 3
 4 176.          -6.61e- 4 -5.86e- 4 1.48e- 3
 5 153.          -7.59e- 4 -6.74e- 4 1.70e- 3
 6 133.          -8.73e- 4 -7.74e- 4 1.96e- 3
 7   0.00287     -9.42e- 1 -1.38e- 1 1.36e+ 0
 8   0.00250     -9.46e- 1 -1.37e- 1 1.36e+ 0
 9   0.00217     -9.50e- 1 -1.37e- 1 1.37e+ 0
10   0.00189     -9.54e- 1 -1.37e- 1 1.37e+ 0
11   0.00164     -9.57e- 1 -1.36e- 1 1.37e+ 0
12   0.00143     -9.59e- 1 -1.36e- 1 1.38e+ 0</code></pre>
</div>
</div>
</section>
<section id="model-selection-15" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="ridge-2">Ridge</h3>
<p>Ridge Logistic Regression parameters <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> path as <span class="math inline">\(\lambda\)</span> increases. Starting from the Logistic Regression MLE for <span class="math inline">\(\lambda=0\)</span> and then shrunken “uniformly” towards zero as <span class="math inline">\(\lambda\)</span> increases.</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-7-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-16" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="lasso">Lasso</h3>
<p>Lasso Estimator is:</p>
<p><span class="math display">\[
\hat \beta_{lasso}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)+\lambda\lVert\beta\rVert_1
\]</span> equivalently::</p>
<p><span class="math display">\[
\hat \beta_{lasso}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)
\]</span> subject to <span class="math inline">\(\lVert\beta\rVert_1 \leq t\)</span>, where <span class="math inline">\(t\)</span> maps to <span class="math inline">\(\lambda\)</span>.</p>
</section>
<section id="model-selection-17" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="lasso-1">Lasso</h3>
<p>Log-likelihood of the Logistic Regression (colored levels lines centered around the MLE) for the Mixture data set, adding the Lasso constraint (the diamond/square in black is the boundary <span class="math inline">\(\lVert\beta\rVert_1 \leq t\)</span>) :</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-8-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-18" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="lasso-2">Lasso</h3>
<p>Lasso Logistic Regression parameters for <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> as a function of <span class="math inline">\(\lambda\)</span>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Fitting Logistic Regression model with Lasso (alpha=1) penalty. Small lambda.min.ratio so that penalty is almost zero at start.</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>mixture_lasso <span class="ot">&lt;-</span> glmnetUtils<span class="sc">::</span><span class="fu">glmnet</span>(Y <span class="sc">~</span> ., <span class="at">data=</span>data_mixture_example, <span class="at">family=</span><span class="st">"binomial"</span>, <span class="at">alpha=</span><span class="dv">1</span>, <span class="at">lambda.min.ratio=</span><span class="fl">0.000001</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="co"># Extracting coefficients</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>lasso_result <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">as.matrix</span>(<span class="fu">cbind</span>(mixture_lasso<span class="sc">$</span>lambda, mixture_lasso<span class="sc">$</span>a0, <span class="fu">t</span>(mixture_lasso<span class="sc">$</span>beta))))</span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="fu">names</span>(lasso_result) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"lambda"</span>, <span class="st">"(Intercept)"</span>, <span class="fu">row.names</span>(mixture_lasso<span class="sc">$</span>beta))</span>
<span id="cb4-6"><a href="#cb4-6"></a><span class="co"># Showing results for very high/low values of lambda</span></span>
<span id="cb4-7"><a href="#cb4-7"></a><span class="fu">bind_rows</span>(lasso_result <span class="sc">%&gt;%</span> <span class="fu">head</span>(), lasso_result <span class="sc">%&gt;%</span> <span class="fu">tail</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 12 × 4
    lambda `(Intercept)`     x1    x2
     &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
 1 0.268       -9.86e-32  0     0    
 2 0.233       -1.03e- 1  0     0.137
 3 0.202       -1.96e- 1  0     0.258
 4 0.176       -2.80e- 1  0     0.368
 5 0.153       -3.57e- 1  0     0.469
 6 0.133       -4.28e- 1  0     0.561
 7 0.00354     -9.63e- 1 -0.122 1.37 
 8 0.00308     -9.65e- 1 -0.124 1.37 
 9 0.00268     -9.67e- 1 -0.125 1.37 
10 0.00233     -9.68e- 1 -0.126 1.38 
11 0.00202     -9.69e- 1 -0.127 1.38 
12 0.00176     -9.70e- 1 -0.128 1.38 </code></pre>
</div>
</div>
</section>
<section id="model-selection-19" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="lasso-3">Lasso</h3>
<p>Lasso Logistic Regression parameters <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> path as <span class="math inline">\(\lambda\)</span> increases. Starting from the Logistic Regression MLE for <span class="math inline">\(\lambda=0\)</span> and as <span class="math inline">\(\lambda\)</span> increases and at some point the solution of the constrained optimization is likely to occur at one of the corners of the diamond.</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-10-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-20" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="lasso-4">Lasso</h3>
<p>Stretching the graph a little bit to better show the Lasso path, the <span class="math inline">\(\beta_1\)</span> parameter is the first shrunk to zero:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-11-1.png" width="960" class="r-stretch"></section>
<section id="model-selection-21" class="slide level2 smaller">
<h2>Model selection</h2>
<h3 id="penalized-logistic-regression-4">Penalized Logistic Regression</h3>
<ul>
<li>Reminding the aim of statistical learning: which method leads to better prediction accuracy?<br>
</li>
<li>In practice, the true set of relevant predictors is unknown: only a few vs many variables possibly correlated)</li>
<li>Resampling methods are to compare models on a given dataset given some criterion and may be used to select a good value of penalization parameters <span class="math inline">\(\lambda\)</span></li>
</ul>
</section></section>
<section>
<section id="model-assessment" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>Model assessment</h1>

</section>
<section id="model-assessment-1" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="resampling-methods">Resampling methods</h3>

<img data-src="../images/james_5-7_polynomial.png" class="r-stretch quarto-figure-center"><p class="caption">Fig 5.7 from <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p></section>
<section id="model-assessment-2" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="resampling-methods-1">Resampling methods</h3>

<img data-src="../images/james_5-8_polynomial.png" class="r-stretch quarto-figure-center"><p class="caption">Fig 5.8 from <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p></section>
<section id="model-assessment-3" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d1">Original Mixture data set (d=1)</h3>
<p>Tried to reproduce results form <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span> using Original Mixture data set with higher Bayes error</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-12-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-4" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d2">Original Mixture data set (d=2)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-13-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-5" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-mixture-data-set-d3">Original Mixture Mixture data set (d=3)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-14-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-6" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d4">Original Mixture data set (d=4)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-15-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-7" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d5">Original Mixture data set (d=5)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-16-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-8" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d6">Original Mixture data set (d=6)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-17-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-9" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d7">Original Mixture data set (d=7)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-18-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-10" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d8">Original Mixture data set (d=8)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-19-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-11" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-d10">Original Mixture data set (d=10)</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-20-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-12" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="original-mixture-data-set-misclassification-curve">Original Mixture data set, misclassification curve</h3>
<p>We plot below the misclassification curve, comparing the misclassification error estimated on a large testing set using the generating distribution (in orange, testing set generated knowing the oracle) with misclassification estimated using a resampling method on the training set (in black, 10-fold Cross Validation, defined later). In our case, we see that misclassification using a resampling method, although optimistic, behaves roughly like misclassification using large testing set:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-21-1.png" width="960" class="r-stretch"></section>
<section id="model-assessment-13" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="the-hold-out-approach">The Hold-out approach</h3>
<p>It consists in splitting the data set into:</p>
<ul>
<li>a learning or training set used to train the classifier or the Score ;</li>
<li>a validation or test set used to estimate the empirical risk of the classifier or any other metric (ROC curve, AUC).</li>
</ul>
<div class="algo">
<p><span class="math display">\[
\begin{aligned}
&amp;1.\ \text{Using a partition of the dataset } \mathcal{D} \text{ into training and validation sets } \{\mathcal{T}, \mathcal{V}\}: \\
&amp;\quad (a)\ \text{Fit the classifiers } f_1, \dots, f_m \text{ on } \mathcal{T} \\
&amp;\quad (b)\ \text{Compute the empirical risk on the validation set:} \\
&amp;\quad\quad \hat{\mathrm{R}}(f) = \frac{1}{n_{\mathcal{V}}} \sum_i \ell(y_i, f_m(x_i)) \\
&amp;\quad\quad \text{or any other chosen metric} \\
\\
&amp;2.\ \text{Select the single best model } f_{m^*} \text{ with respect to the empirical risk or metric}
\end{aligned}
\]</span></p>
</div>
</section>
<section id="model-assessment-14" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="the-hold-out-approach-1">The Hold-out approach</h3>

<img data-src="../images/james_5-1_holdout.png" class="r-stretch quarto-figure-center"><p class="caption">Fig 5.1 from <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p><p>The main drawback using a single split of data is the possible variability of empirical risk, which is more pregnant when the data set size reduces. Against this issue an alternative approach is to repeat this process on multiple splits of the data.</p>
</section>
<section id="model-assessment-15" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="the-k-fold-cross-validation-approach">The K-fold Cross-Validation approach</h3>
<p>It consists in splitting randomly the data set into <span class="math inline">\(K\)</span> blocks of folds then repeating <span class="math inline">\(K\)</span> times the Hold-out approach, each time using a different block as validation set.</p>
<div class="algo">
<p><span class="math display">\[
\begin{aligned}
&amp;1.\ \text{Partition the dataset } \mathcal{D} \text{ randomly into } K \text{ blocks } \{\mathcal{D}_1, \dots, \mathcal{D}_K\} \\
\\
&amp;2.\ \text{For } k = 1, \dots, K: \\
&amp;\quad (a)\ \text{Define training and validation sets: } \mathcal{V}_k = \mathcal{D}_k, \ \mathcal{T}_k = \mathcal{D} \setminus \mathcal{D}_k \\
&amp;\quad (b)\ \text{Fit the classifiers } f_1, \dots, f_m \text{ on } \mathcal{T}_k \\
&amp;\quad (c)\ \text{Compute the empirical risk on the validation set:} \\
&amp;\quad\quad \hat{\mathrm{R}}(f) = \frac{1}{n_{\mathcal{V}_k}} \sum_i \ell(y_i, f_m(x_i)) \\
&amp;\quad\quad \text{or any other chosen metric} \\
\\
&amp;3.\ \text{Select the single best model } f_{m^*} \text{ using the average empirical risk or metric}
\end{aligned}
\]</span></p>
</div>
</section>
<section id="model-assessment-16" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="the-k-fold-cross-validation-approach-1">The K-fold Cross-Validation approach</h3>

<img data-src="../images/james_5-5_cv.png" class="r-stretch quarto-figure-center"><p class="caption">Fig 5.5 from <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span></p></section>
<section id="model-assessment-17" class="slide level2 smaller">
<h2>Model assessment</h2>
<h3 id="the-k-fold-cross-validation-approach-2">The K-fold Cross-Validation approach</h3>
<p>A variant is to first split the data set into a training and validation set. Perform K-fold Cross-Validation on the training set, for example to select some classifier hyper parameter (number of variables or model specification in logistic regression, penalty, etc), then assess the best “optimized” models on the validation set.</p>
<p>Another variant is to repeat the K-fold CV 5 or 10 times to improve the accuracy of the estimated performance and provide and estimate on its variability.</p>
<p>This <a href="https://bradleyboehmke.github.io/HOML/process.html">book chapter</a> gives a practical overview on these methods (how to implement it in R) and also gives references discussing their validity and limitations.</p>
<p>This <a href="https://developer.nvidia.com/blog/the-kaggle-grandmasters-playbook-7-battle-tested-modeling-techniques-for-tabular-data/">recent blog by NVIDIA Kaggle grandmasters</a> advocates resampling techniques (cross-validation) as a foundation for any supervized learning problem.</p>
</section></section>
<section>
<section id="a-short-intro-to-decision-trees" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>A short intro to Decision Trees</h1>

</section>
<section id="a-short-intro-to-decision-trees-1" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="mixture-data-set-logistic-regression">Mixture data set: Logistic Regression</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-22-1.png" width="960" class="r-stretch"><p>The empirical risk on testing set is 0.291.</p>
</section>
<section id="a-short-intro-to-decision-trees-2" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="toy-example---logistic-regression---binning">Toy example - Logistic Regression - binning</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-23-1.png" width="960" class="r-stretch"><p>The empirical risk on testing set is 0.265.</p>
</section>
<section id="a-short-intro-to-decision-trees-3" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="toy-example---decision-trees">Toy example - Decision Trees</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-25-1.png" width="960" class="r-stretch"><p>The empirical risk on testing set is 0.247.</p>
</section>
<section id="a-short-intro-to-decision-trees-4" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="scoring-toy-example---decision-trees">Scoring Toy example - Decision Trees</h3>
<p>We show below the previously fitted Decision tree:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-26-1.png" width="960" class="r-stretch"><p>How to fit such a tree? What criterion is used?</p>
</section>
<section id="a-short-intro-to-decision-trees-5" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="trees-terminology">Trees Terminology</h3>
<p>Decision trees recursively partition the data by applying specific cutoff values to the features. This process creates various subsets of the data set, with each data point belonging to one of these subsets. The final subsets are known as Terminal or Leaf nodes, while the intermediate ones are referred to as Internal, Split or Decision nodes.</p>

<img data-src="../images/decison_tree.png" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-6" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart">CART</h3>
<p>Classification And Regression Tree (CART) (<span class="citation" data-cites="Breiman83">Breiman et al. (<a href="#/references" role="doc-biblioref" onclick="">1983</a>)</span>), is a recursive method:</p>
<ul>
<li><p>At the root of the tree we find the entire sample.</p></li>
<li><p>Each node of the tree divides the sample into 2 branches, according to a feature variable (discrete, continuous or ordinal variable (threshold) or a nominal variable (set of categories)).</p></li>
<li><p>A terminal node is called a leaf. Usually the tree is represented upside down with its root at the top</p></li>
</ul>
<p>The tree is built by the following process:</p>
<ul>
<li>First find the single variable which ‘best’ <strong>splits</strong> the data into two groups (‘best’ will be defined later).</li>
<li>The data is separated, and then this process is applied separately to each sub-group, and so on recursively until a <strong>stopping rule</strong> occurs (either no improvement can be made or the subgroups reach a minimum size).</li>
</ul>
</section>
<section id="decision-trees" class="slide level2 smaller">
<h2>Decision Trees</h2>
<h3 id="cart-for-mixture-data-set">CART for Mixture data set</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-27-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-7" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-1">CART for Mixture data set</h3>
<p>Starting from the top of the tree and going down the <code>CART/rpart</code> algorithm splits at each node according to a binary decision.</p>
<p>It ends up splitting the space into six regions, and then models the output by the mode/majority (classification) or proportion (scoring/probability) of <span class="math inline">\(Y\)</span> in each region:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-28-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-8" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-2">CART for Mixture data set</h3>
<p>For example, with the Mixture data, <code>CART/rpart</code> first splits at <span class="math inline">\(x_2=s_1=0.14\)</span>:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-29-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-9" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-3">CART for Mixture data set</h3>
<p>Then, the region <span class="math inline">\(x_2 \geq s_1\)</span> is split at <span class="math inline">\(x_1 = s_2 = 2.2\)</span>:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-30-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-10" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-4">CART for Mixture data set</h3>
<p>Then, the region <span class="math inline">\(x_2 \geq s_1, \mbox{ } x_1 &gt; s_2\)</span> is split at <span class="math inline">\(x_1 = s_3 = 3.1\)</span>:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-31-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-11" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-5">CART for Mixture data set</h3>
<p>And the region <span class="math inline">\(x_2 \geq s_1, \mbox{ } x_1 \leq s_2\)</span> is split at <span class="math inline">\(x_2 = s_4 = 0.98\)</span>:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-32-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-12" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="cart-for-mixture-data-set-6">CART for Mixture data set</h3>
<p>Finally the region <span class="math inline">\(x_2 \geq s_1, \mbox{ } x_1 \leq s_2, \mbox{ } x_2 &lt; s_4\)</span> is split at <span class="math inline">\(x_1 = s_5 = 1\)</span>. Resulting in <span class="math inline">\(R_1, R_2, . . . , R_6\)</span> shown below:</p>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-33-1.png" width="960" class="r-stretch"></section>
<section id="decision-trees-1" class="slide level2 smaller">
<h2>Decision Trees</h2>
<h3 id="splitting-criterion">Splitting criterion</h3>
<p>In order to classify well the data, CART seeks as much as possible to obtain pure leaf nodes (i.e.&nbsp;high probability for one class).</p>
<p>At each step CART selects a predictor <span class="math inline">\(X_j\)</span> and a split-point <span class="math inline">\(s\)</span> such that splitting the current region <span class="math inline">\(\mathcal R\)</span> into the regions <span class="math inline">\(\mathcal R_L(j,s)=\{X|Xj &lt; s\}\)</span> and <span class="math inline">\(\mathcal R_R(j,s)=\{X|Xj ≥ s\}\)</span> leads to the greatest possible reduction in a well chosen measure of impurity.</p>
<p>Given a leaf node <span class="math inline">\(m\)</span> representing a region <span class="math inline">\(R_m\)</span> containing <span class="math inline">\(n_m\)</span> observations we denote <span class="math inline">\(\mathcal I_m\)</span> a measure of node impurity, three measures are usually retained:</p>
<ul>
<li><p>the misclassification error: <span class="math inline">\(\mathcal I_m =\frac{1}{n_m}\sum_{x_i \in R_m}\mathbb{1}_{y_i\neq \hat C_m}= 1-\hat p^m_{\hat C_m}=1-\max(\hat p^m, 1-\hat p^m)\)</span> the fraction of observations in the region that do not belong to the most common class</p></li>
<li><p>the Gini index: <span class="math inline">\(\mathcal I_m=\sum_{k}\hat p^m_{k}(1-\hat p^m_{k})=2\hat p^m(1-\hat p^m)\)</span></p></li>
<li><p>the cross-entropy or deviance: <span class="math inline">\(\mathcal I_m=-\sum_{k} \hat p^m_{k}\log(1-\hat p^m_{k})=-\hat p^m\log(\hat p^m)- (1-\hat p^m)\log(1-\hat p^m)\)</span></p></li>
</ul>
<p>where we have denoted <span class="math inline">\(\hat p^m=\hat p^m_{1}=1-\hat p^m_{0}\)</span></p>
</section>
<section id="a-short-intro-to-decision-trees-13" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="impurity-measures">Impurity measures</h3>

<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-34-1.png" width="960" class="r-stretch"></section>
<section id="a-short-intro-to-decision-trees-14" class="slide level2 smaller">
<h2>A short intro to Decision Trees</h2>
<h3 id="a-split-example">A split example</h3>
<div class="cell">

<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 6
  feature_split split_rule imp_left imp_right imp_total imp_node
  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 x2                 0.151    0.142     0.456     0.374      0.5</code></pre>
</div>
</div>
<img data-src="3_logreg_var_sel_files/figure-revealjs/unnamed-chunk-35-1.png" width="960" class="r-stretch"></section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-Breiman83" class="csl-entry" role="listitem">
Breiman, L., Friedman, J. H., Olshen, R. A., &amp; Stone, C. J. and. (1983). <em>Classification and regression trees</em>. Wadsworth.
</div>
<div id="ref-hastie2009" class="csl-entry" role="listitem">
Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). <em>The elements of statistical learning</em>. Springer New York. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>
</div>
<div id="ref-islr2021" class="csl-entry" role="listitem">
James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2021). <em>An introduction to statistical learning: With applications in r</em>. Springer US. <a href="https://doi.org/10.1007/978-1-0716-1418">https://doi.org/10.1007/978-1-0716-1418</a>
</div>
</div>
<div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="3_logreg_var_sel_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="3_logreg_var_sel_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>