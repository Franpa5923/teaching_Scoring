<!DOCTYPE html>
<html lang="en"><head>
<script src="2_logreg_files/libs/clipboard/clipboard.min.js"></script>
<script src="2_logreg_files/libs/quarto-html/tabby.min.js"></script>
<script src="2_logreg_files/libs/quarto-html/popper.min.js"></script>
<script src="2_logreg_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="2_logreg_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="2_logreg_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="2_logreg_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="2_logreg_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.450">

  <meta name="author" content="Louis Olive">
  <meta name="dcterms.date" content="2025-09-23">
  <title>Scoring</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="2_logreg_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="2_logreg_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="2_logreg_files/libs/revealjs/dist/theme/quarto.css">
  <link href="2_logreg_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="2_logreg_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="2_logreg_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="2_logreg_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Scoring</h1>
  <p class="subtitle">M2 D3S/EGR 2025-2026</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Louis Olive 
</div>
<div class="quarto-title-author-email">
<a href="mailto:louis.olive@gmail.com / louis.olive@ut-capitole.fr">louis.olive@gmail.com / louis.olive@ut-capitole.fr</a>
</div>
</div>
</div>

  <p class="date">September 23, 2025</p>
</section>
<section>
<section id="outline" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>Outline</h1>
<!-- Quick and dirty -->
<!-- Lightbox Figures not working with Revealjs / https://quarto.org/docs/output-formats/html-lightbox-figures.html -->
<!-- https://stackoverflow.com/questions/56361986/zoom-function-in-rmarkdown-html-plot/59401761#59401761 -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js" "=""></script>
<script type="text/javascript">
  $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
</script>
</section>
<section id="outline-1" class="slide level2">
<h2>Outline</h2>
<div class="extrapad">
<ul>
<li>The Logistic Regression model</li>
</ul>
</div>
</section></section>
<section>
<section id="the-logistic-regression-model" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>The Logistic Regression model</h1>

</section>
<section id="the-logistic-regression-model-1" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example">Informal introductory example</h3>
<p>We provide here some intuitions leading to the Logistic Regression model using a simulated data set from <span class="citation" data-cites="islr2021">James et al. (<a href="#/references" role="doc-biblioref" onclick="">2021</a>)</span> (the <strong>Default</strong> data set).</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># Default data set (simulated) from ESLII/ISLR</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>default_data <span class="ot">&lt;-</span> ISLR2<span class="sc">::</span>Default <span class="sc">%&gt;%</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>    <span class="fu">as_tibble</span>()</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="fu">glimpse</span>(default_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 10,000
Columns: 4
$ default &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, No, No, No, No…
$ student &lt;fct&gt; No, Yes, No, No, No, Yes, No, Yes, No, No, Yes, Yes, No, No, N…
$ balance &lt;dbl&gt; 729.5265, 817.1804, 1073.5492, 529.2506, 785.6559, 919.5885, 8…
$ income  &lt;dbl&gt; 44361.625, 12106.135, 31767.139, 35704.494, 38463.496, 7491.55…</code></pre>
</div>
</div>
<p>This is a toy data set used for teaching purposes containing information on ten thousand customers.</p>
<p>The aim here is to assess which customers will <strong><em>default</em></strong> on their credit card debt (the target or response variable) based on the current credit card <strong><em>balance</em></strong> and other individual characteristics (the predictors or feature vector).</p>
</section>
<section id="the-logistic-regression-model-2" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-1">Informal introductory example</h3>
<p>We can start to explore the Default data with a scatterplot (<a href="#/fig-default_balance-scatterplot">Figure&nbsp;1</a>) of the target variable (<strong><em>default</em></strong>) with respect to a predictor (<strong><em>balance</em></strong>):</p>

<img data-src="2_logreg_files/figure-revealjs/fig-default_balance-scatterplot-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Figure&nbsp;1: Scatterplot of variable <strong><em>default</em></strong> with respect to credit card <strong><em>balance</em></strong> for 10000 customers</p></section>
<section id="the-logistic-regression-model-3" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-2">Informal introductory example</h3>
<p>In this scatterplot, all points fall on one of two parallel lines representing the absence (No) or occurrence (Yes) of <strong><em>default</em></strong>. We “jitter” the data vertically to avoid overplotting. The plot below shows that the response variable is imbalanced towards the absence of default:</p>

<img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-4-1.png" width="960" class="r-stretch"></section>
<section id="the-logistic-regression-model-4" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-3">Informal introductory example</h3>
<p>We also show the boxplots of credit cards <strong><em>balance</em></strong> with respect to <strong><em>default</em></strong> status:</p>

<img data-src="2_logreg_files/figure-revealjs/fig-balance_default-boxplot-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Figure&nbsp;2: Variable <strong><em>balance</em></strong> with respect to <strong><em>default</em></strong> status</p><p>We can see from <a href="#/fig-default_balance-scatterplot">Figure&nbsp;1</a> and <a href="#/fig-balance_default-boxplot">Figure&nbsp;2</a> that default tends to be more prevalent for accounts with a high balance. However it is difficult to guess a simple relationship between default and balance.</p>
</section>
<section id="the-logistic-regression-model-5" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-4">Informal introductory example</h3>
<p>To investigate further we discretise the balance variables by classes of width <span class="math inline">\(300\$\)</span> and compute the mean of response variable (<strong><em>default</em></strong> is Yes) within each balance class:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 9 × 6
  balance_bins   min   max    No   Yes `Mean(default)`
  &lt;fct&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;           &lt;dbl&gt;
1 [0,300)          0   300  1497     0          0     
2 [300,600)      300   600  1784     0          0     
3 [600,900)      600   900  2305     3          0.0013
4 [900,1200)     900  1200  2098    19          0.009 
5 [1200,1500)   1200  1500  1330    53          0.0383
6 [1500,1800)   1500  1800   527    96          0.154 
7 [1800,2100)   1800  2100   115   114          0.498 
8 [2100,2400)   2100  2400    11    41          0.788 
9 [2400,2700)   2400  2700     0     7          1     </code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-6" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-5">Informal introductory example</h3>
<p>Then we plot the mean of default (in red) within each balance class (of width <span class="math inline">\(300\$\)</span>):</p>

<img data-src="2_logreg_files/figure-revealjs/fig-balance_default-scatterplot-occurrence-1.png" width="960" class="r-stretch quarto-figure-center"><p class="caption">Figure&nbsp;3: Mean occurrence of <strong><em>default</em></strong> within <strong><em>balance</em></strong> classes</p><p>The relationship between the mean occurrence of <strong><em>default</em></strong> and <strong><em>balance</em></strong> is easier to read.</p>
<p><a href="#/fig-balance_default-scatterplot-occurrence">Figure&nbsp;3</a> clearly shows that as balance increases, the proportion of customers defaulting on their credit card increases.</p>
</section>
<section id="the-logistic-regression-model-7" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-6">Informal introductory example</h3>

<img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-8-1.png" width="960" class="r-stretch"><p>We also notice that the mean default occurrence with respect to balance classes follows a kind of “S”-shaped curve or <strong>sigmoid</strong> function. Going further and informally, considering that the mean of default occurrence is an estimate of <span class="math inline">\(\mathbf{E}[Y|X=x]\)</span> for each balance classes an idea would be to model:</p>
<p><span class="math display">\[
\mathbb{E}[Y|X=x] = \mu_\beta(x)
\]</span></p>
<p>where <span class="math inline">\(\mu_\beta\)</span> is a <strong>sigmoid</strong> function in <span class="math inline">\([0,1]\)</span>.</p>
</section>
<section id="the-logistic-regression-model-8" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="informal-introductory-example-7">Informal introductory example</h3>
<p>The Logistic Regression model uses the <strong>sigmoid</strong> function <span class="math inline">\(\sigma: x \to\sigma(x)=\frac{e^{x}} { 1 + e^{x} }\)</span> also known as the logistic function. Below a simple transform of this logistic function has been “fitted” (blue dots) to the <code>default ~ balance</code> data set:</p>

<img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-9-1.png" width="960" class="r-stretch"></section>
<section id="the-logistic-regression-model-9" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="a-more-formal-definition---the-discriminative-approach">A more formal definition - the discriminative approach</h3>
<p>Reminding the statistical learning / scoring concepts introduced before. We try to predict the output <code>default</code> (<span class="math inline">\(Y \in \{0,1\}\)</span>) using a training set of inputs <span class="math inline">\(X\)</span>: this is a binary classification problem.</p>
<p>We remind that to estimate an optimal classifier for output <span class="math inline">\(Y \in \{0,1\}\)</span> using input <span class="math inline">\(X = (X_1,\cdots,X_p)\)</span> one approach was to:</p>
<ul>
<li><p>model the conditional distribution <span class="math inline">\(Y|X\)</span> (the <strong>discriminative</strong> approach),</p></li>
<li><p>estimate <span class="math inline">\(\eta(x)\)</span> with:</p></li>
</ul>
<p><span class="math display">\[
\eta(x)=\mathbb{P}[Y=1|X=x)] = \mathbb{E}[Y=1|X=x)]
\]</span></p>
<ul>
<li><p><span class="math inline">\(\eta(x)\)</span> can be used as a Scoring function</p></li>
<li><p>define the classifier <span class="math inline">\(f_s\)</span> using a cutoff <span class="math inline">\(s\)</span> and Scoring function <span class="math inline">\(\eta(x)\)</span> to predict output <span class="math inline">\(Y\)</span>:</p></li>
</ul>
<p><span class="math display">\[
f_s(x)=\left\{ \begin{array}{ll}
    1 &amp;  \mbox{if } \eta(x)\geq s\cr
    0 &amp;  \mbox{otherwise}\cr
\end{array} \right.
\]</span></p>
</section>
<section id="the-logistic-regression-model-10" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="a-more-formal-definition">A more formal definition</h3>
<p>In the case of <strong>Logistic Regression</strong> classifier, we model:</p>
<p><span class="math display">\[
Y|X=x~ \sim B(\eta(x))
\]</span></p>
<p>with</p>
<p><span class="math display">\[
\eta(x)=\sigma(x^T\beta) =\frac{exp(x^T\beta)}{1+exp(x^T\beta)}
\]</span></p>
<p>for some parameter <span class="math inline">\(\beta=(\beta_1,\cdots,\beta_p)\in \mathbb R^p\)</span>, usually <span class="math inline">\(x_1=1\)</span> and <span class="math inline">\(\beta_1\)</span> is an intercept. <span class="math inline">\(\sigma\)</span> is the sigmoid logistic function we have seen before.</p>
<p>In the literature is usual to denote <span class="math inline">\(\eta(X)=p_{\beta}(X)\)</span> or <span class="math inline">\(\eta(X)=\pi_{\beta}(X)\)</span>.</p>
<p>From now, we will use the notation <span class="math inline">\(p_{\beta}(X)\)</span>.</p>
</section>
<section id="the-logistic-regression-model-11" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="a-more-formal-definition-1">A more formal definition</h3>
<p>Defining <span class="math inline">\(\mathrm{logit}: x \to \log\bigg( \frac{x}{1-x}\bigg)\)</span>, which is the inverse of <span class="math inline">\(\sigma\)</span> the logistic function (show it as an exercise), we have:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(X))=X^T\beta
\]</span></p>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>The <strong>Logistic Regression</strong> model:</strong></p>
</div>
<div class="callout-content">
<p>We are given <span class="math inline">\((x_i, y_i) \in \mathbb R^p \times \{0,1\}\)</span>, <span class="math inline">\(i=1,\cdots,n\)</span></p>
<p>The Logistic Regression model assumes that outputs <span class="math inline">\(y_i\)</span> are independent Bernoulli with parameter <span class="math inline">\(p_{\beta}(x_i)\)</span> depending on <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x_i))=x_i^T\beta
\]</span></p>
</div>
</div>
</div>
</section>
<section id="the-logistic-regression-model-13" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="how-to-fit-with-r">How to fit with R</h3>
<p>The syntax to fit the Logistic model in R using <code>glm()</code> is:</p>
<p><span class="math display">\[
\mathtt{glm(} \mathrm{y} \sim \mathrm{~x,~}\mathtt{data=}~\mathrm{dataframe,~}\mathtt{family~=~binomial(link~=~"logit")}
\]</span></p>
<p>The formula <span class="math inline">\(\mathrm{y} \sim \mathrm{x}\)</span> depicts the model (i.e.&nbsp;inputs are <span class="math inline">\(X\)</span>, output is <span class="math inline">\(Y\)</span>) and the <code>data=</code> argument points to the training set contained in a R dataframe (or tibble). This is quite similar to the <code>lm()</code> function.</p>
<p>We also need to specify the distribution for the conditional <span class="math inline">\(Y\)</span> values (binomial) and the link function (logit) via the <code>family=</code> argument.</p>
</section>
<section id="the-logistic-regression-model-14" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="how-to-fit-with-r-1">How to fit with R</h3>
<p>For our default example:</p>
<p>The command <code>summary</code> produces result summaries of the fitted model:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>We will see in the next lesson, how this model is fitted in practice and how to interpret or understand what is printed by the <code>summary</code> function.</p>
</section>
<section id="the-logistic-regression-model-15" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation">Estimation</h3>
<p>We are given <span class="math inline">\((x_i, y_i) \in \mathbb R^p \times \{0,1\}\)</span>, <span class="math inline">\(i=1,\cdots,n\)</span> where outputs <span class="math inline">\(y_i\)</span> are independent Bernoulli with parameter <span class="math inline">\(p_{\beta}(x_i)\)</span> depending on <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x_i))=x_i^T\beta
\]</span></p>
<p>The parameters <span class="math inline">\(\beta\)</span> of the Logistic Regression model are usually determined using Maximum Likelihood Estimation (MLE). It consists on finding <span class="math inline">\(\beta\)</span> for which the joint probability of the observed data is greatest.</p>
<p>As <span class="math inline">\(y_i\)</span> are independent the likelihood function (joint probability) is the product of the probability mass functions:</p>
<p><span class="math display">\[
L(Y,\beta) = \prod_{i=1}^n p_{\beta}(x_i)^{y_i}(1-p_{\beta}(x_i))^{1-y_i}
\]</span></p>
<p>with <span class="math inline">\(Y=(y_1,\cdots,y_n)\)</span> and <span class="math inline">\(\beta=(\beta_1,\cdots,\beta_p)\)</span>.</p>
</section>
<section id="the-logistic-regression-model-16" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation-1">Estimation</h3>
<p>We seek to maximize the likelihood function over <span class="math inline">\(\beta\)</span>, it is equivalent but easier to maximize the log-likelihood:</p>
<p><span class="math display">\[
\begin{align}
\ell(Y,\beta)=\log L(Y,\beta) &amp;=\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right) \\
                              &amp;=\sum_{i=1}^{n} \left(y_i \log(\frac{p_{\beta}(x_i)}{1-p_{\beta}(x_i)})+\log(1- p_{\beta}(x_i))\right)\\
                              &amp;=\sum_{i=1}^{n} \left(y_i x_i^T\beta -\log(1 + \exp(x_i^T\beta)\right)
\end{align}
\]</span></p>
<p>If the MLE <span class="math inline">\(\hat\beta\)</span> exists, the gradient of log-likelihood satisfies (first order necessary condition):</p>
<p><span class="math display">\[
\nabla\ell(Y,\beta)=\left(\frac{\partial \ell(Y,\beta)}{\partial \beta_1}, \cdots,\frac{\partial \ell(Y,\beta)}{\partial \beta_p}\right)=\mathbf 0
\]</span></p>
</section>
<section id="the-logistic-regression-model-17" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation-2">Estimation</h3>
<p>We have for <span class="math inline">\(j=1,\cdots,p\)</span>:</p>
<p><span class="math display">\[
\frac{\partial \ell(Y,\beta)}{\partial \beta_j}=\sum_{i=1}^{n} \left(y_i x_{ij} -x_{ij}\frac{\exp(x_i^T\beta)}{1+\exp(x_i^T\beta)}\right)=\sum_{i=1}^{n} x_{ij} \left(y_i- p_{\beta}(x_i)\right)
\]</span></p>
<p>In vector form:</p>
<p><span class="math display">\[
\nabla\ell(Y,\beta)=\sum_{i=1}^{n} x_{i} \left(y_i- p_{\beta}(x_i)\right)=X^T(Y-P_{\beta})
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\begin{aligned}
X = \begin{pmatrix}
x_{11} &amp; \cdots &amp; x_{1p} \\
x_{21} &amp; \cdots &amp; x_{2p} \\
\vdots  &amp; \vdots  &amp; \vdots   \\
x_{n1} &amp; \cdots &amp; x_{np}
\end{pmatrix} =
\begin{pmatrix}
x_1^T\\
x_2^T\\
\vdots \\
x_n^T
\end{pmatrix}\in \mathbb{R}^{n\times (p)}, \quad
Y = \begin{pmatrix}
y_{1} \\
y_{2}\\
\vdots \\
y_{n}  
\end{pmatrix} \quad and \quad
P_{\beta} = \begin{pmatrix}
p_{\beta}(x_1) \\
p_{\beta}(x_2)\\
\vdots \\
p_{\beta}(x_n)  
\end{pmatrix}
\end{aligned}
\]</span></p>
</section>
<section id="the-logistic-regression-model-18" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation-3">Estimation</h3>
<p>In the literature <span class="math inline">\(\nabla\ell(Y,\beta)\)</span> is denoted as the Fisher’s score function <span class="math inline">\(S(\beta)\)</span>.</p>
<p>If the MLE <span class="math inline">\(\hat\beta\)</span> exists, we have:</p>
<p><span class="math display">\[
S(\hat\beta)=\nabla\ell(Y,\hat\beta)=X^T(Y-P_{\hat\beta})=0
\]</span></p>
<p>Solving this equation involves solving <span class="math inline">\(p\)</span> non-linear equations in <span class="math inline">\(\beta=(\beta_1,\cdots,\beta_p)\)</span>:</p>
<p><span class="math display">\[
y_1 x_{1j} + \cdots + y_n x_{nj} = x_{1j}\frac{\exp(x_1^T\beta)}{1+\exp(x_1^T\beta)}+ \cdots + x_{nj}\frac{\exp(x_n^T\beta)}{1+\exp(x_n^T\beta)},\quad j=1,\cdots,p
\]</span> Numerical methods are used to solve these non-linear equations as no closed-form solution exist.</p>
</section>
<section id="the-logistic-regression-model-19" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---mle-existence">Estimation - MLE existence</h3>
<p>If we assume that <span class="math inline">\(rank(X)=p\)</span>, we have that <span class="math inline">\(S(\beta)\)</span> is concave in <span class="math inline">\(\beta\)</span> hence if we find a local maximum it is a global maximum.</p>
<p>We have for <span class="math inline">\((k,l) \in (1,\cdots,p)^2\)</span>:</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial\mathcal \ell}{\partial\beta_k\partial\beta_l}(\beta)= &amp; \frac{\partial}{\partial\beta_k}
\sum_{i=1}^nx_{il}(y_i-\frac{\exp(x_i^T\beta)}{1+\exp(x_i^T\beta)}) \\
=&amp; -\sum_{i=1}^nx_{il}x_{ik}\frac{\exp(x_i^T\beta)}{(1+\exp(x_i^T\beta))^2} \\
=&amp; -\sum_{i=1}^nx_{ik}p_\beta(x_i)(1-p_\beta(x_i))x_{il}
\end{align}
\]</span></p>
</section>
<section id="the-logistic-regression-model-20" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---mle-existence-1">Estimation - MLE existence</h3>
<p>We obtain that in matrix form:</p>
<p><span class="math display">\[
H(\beta)=\nabla^2\ell(Y,\beta)=-X^T W_\beta X
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\begin{align}
W_\beta = \begin{pmatrix}
p_\beta(x_1)(1-p_\beta(x_1)) &amp; \cdots &amp; \cdots\\
\vdots  &amp; \ddots &amp; \vdots \\
\cdots  &amp; \cdots &amp; p_\beta(x_n)(1-p_\beta(x_n))
\end{pmatrix}
\end{align}
\]</span></p>
<p>We have <span class="math inline">\(p_\beta(x_i)(1-p_\beta(x_i))\geq0\)</span> hence <span class="math inline">\(W(\beta)\)</span> is semi-definite negative and since <span class="math inline">\(rank(X)=p\)</span>, <span class="math inline">\(H(\beta)\)</span> is concave.</p>
</section>
<section id="the-logistic-regression-model-21" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---mle-existence-2">Estimation - MLE existence</h3>
<p>It is shown in <span class="citation" data-cites="albert1984a">(<a href="#/references" role="doc-biblioref" onclick="">Albert &amp; Aanderson, 1984</a>)</span> that if additionally there is no complete separation in the training set:</p>

<img data-src="../images/unique_mle.png" class="r-stretch"><p>then the MLE exists and is unique, we will denote it <span class="math inline">\(\hat\beta\)</span>.</p>
</section>
<section id="the-logistic-regression-model-22" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---the-newton-raphson-method">Estimation - The Newton-Raphson method</h3>
<p>In practice a numerical/iterative method such as the Newton-Raphson method is used to solve the equation:</p>
<p><span class="math display">\[
S(\beta)=\nabla\ell(Y,\beta)=X^T(Y-P_{\beta})=0
\]</span></p>
<p>Using Taylor expansion of Score <span class="math inline">\(S(\beta)\)</span> around an initial guess <span class="math inline">\(\beta^{(0)}\)</span> of <span class="math inline">\(\hat\beta\)</span>: <span class="math display">\[
S(\hat\beta) \approx S(\beta^{(0)})+H(\beta^{(0)})(\hat\beta-\beta^{(0)})
\]</span> giving a first estimate of <span class="math inline">\(\hat\beta\)</span>: <span class="math display">\[
\beta^{(1)} = \beta^{(0)} - H^{-1}(\beta^{(0)})S(\beta^{(0)})
\]</span> Then until convergence, the Newton-Raphson method iterates:</p>
<p><span class="math display">\[
\beta^{(k+1)} = \beta^{(k)} - H^{-1}(\beta^{(k)})S(\beta^{(k)})
\]</span></p>
</section>
<section id="the-logistic-regression-model-23" class="slide level2 smaller scrollable">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---the-newton-raphson-method-1">Estimation - The Newton-Raphson method</h3>
<p>We show below a naive implementation of Newton-Raphson method to estimate <span class="math inline">\(\beta\)</span>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># We put the data frame in matrix form</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co"># also adding an intercept</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(default_data)),</span>
<span id="cb5-4"><a href="#cb5-4"></a>                          <span class="fu">as.matrix</span>(default_data <span class="sc">%&gt;%</span> <span class="fu">select</span>(balance, income))) </span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"balance"</span>, <span class="st">"income"</span>)</span>
<span id="cb5-6"><a href="#cb5-6"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb5-7"><a href="#cb5-7"></a></span>
<span id="cb5-8"><a href="#cb5-8"></a><span class="co"># We extract the output as vector</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>Y <span class="ot">&lt;-</span> default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default<span class="sc">==</span><span class="st">'Yes'</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(default)</span>
<span id="cb5-10"><a href="#cb5-10"></a></span>
<span id="cb5-11"><a href="#cb5-11"></a><span class="co"># We set an initial guess for beta and criterion for stopping</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>)</span>
<span id="cb5-13"><a href="#cb5-13"></a>nb_iter <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>tol <span class="ot">&lt;-</span> <span class="fl">1e-4</span></span>
<span id="cb5-15"><a href="#cb5-15"></a></span>
<span id="cb5-16"><a href="#cb5-16"></a>lr_solve <span class="ot">&lt;-</span> <span class="cf">function</span>(X, Y, beta, nb_iter, tol){</span>
<span id="cb5-17"><a href="#cb5-17"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nb_iter){</span>
<span id="cb5-18"><a href="#cb5-18"></a>        <span class="co"># first compute p_beta(X)</span></span>
<span id="cb5-19"><a href="#cb5-19"></a>        p_beta <span class="ot">&lt;-</span> <span class="fu">exp</span>(X <span class="sc">%*%</span> beta) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(X <span class="sc">%*%</span> beta))</span>
<span id="cb5-20"><a href="#cb5-20"></a>        <span class="co"># then the Score</span></span>
<span id="cb5-21"><a href="#cb5-21"></a>        Score_beta <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> (Y<span class="sc">-</span>p_beta)</span>
<span id="cb5-22"><a href="#cb5-22"></a>        <span class="co"># and the Hessian</span></span>
<span id="cb5-23"><a href="#cb5-23"></a>        W_beta <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, n, n)</span>
<span id="cb5-24"><a href="#cb5-24"></a>        <span class="fu">diag</span>(W_beta) <span class="ot">&lt;-</span> p_beta<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p_beta)</span>
<span id="cb5-25"><a href="#cb5-25"></a>        Hessian_beta <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">t</span>(X) <span class="sc">%*%</span> W_beta <span class="sc">%*%</span> X</span>
<span id="cb5-26"><a href="#cb5-26"></a>        <span class="co"># we update beta</span></span>
<span id="cb5-27"><a href="#cb5-27"></a>        new_beta <span class="ot">&lt;-</span> beta <span class="sc">-</span> <span class="fu">solve</span>(Hessian_beta) <span class="sc">%*%</span> Score_beta</span>
<span id="cb5-28"><a href="#cb5-28"></a>        <span class="co"># we check for convergence</span></span>
<span id="cb5-29"><a href="#cb5-29"></a>        <span class="cf">if</span>(<span class="fu">t</span>(beta<span class="sc">-</span>new_beta) <span class="sc">%*%</span> (beta<span class="sc">-</span>new_beta) <span class="sc">&lt;</span> tol){</span>
<span id="cb5-30"><a href="#cb5-30"></a>            <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">beta =</span> beta, <span class="at">hessian =</span> Hessian_beta, <span class="at">nb_iter =</span> i)) </span>
<span id="cb5-31"><a href="#cb5-31"></a>        }</span>
<span id="cb5-32"><a href="#cb5-32"></a>        beta <span class="ot">&lt;-</span> new_beta</span>
<span id="cb5-33"><a href="#cb5-33"></a>    }</span>
<span id="cb5-34"><a href="#cb5-34"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">beta =</span> beta, <span class="at">hessian =</span> Hessian_beta, <span class="at">nb_iter =</span> i)) </span>
<span id="cb5-35"><a href="#cb5-35"></a>}</span>
<span id="cb5-36"><a href="#cb5-36"></a>sol <span class="ot">&lt;-</span> <span class="fu">lr_solve</span>(X, Y, beta, nb_iter, tol)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="the-logistic-regression-model-24" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---the-newton-raphson-method-2">Estimation - The Newton-Raphson method</h3>
<p>We verify that the R <code>glm()</code> function and our algorithm give close values for coefficients <span class="math inline">\(\beta\)</span>:</p>
<ul>
<li>R <code>glm()</code>:</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     balance      income 
 -11.540468    0.005647    0.000021 </code></pre>
</div>
</div>
<ul>
<li>Newton-Raphson:</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>     (Intercept)  balance  income
[1,]   -11.53791 0.005646 2.1e-05</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-25" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="estimation---machine-learning-approach">Estimation - Machine Learning approach</h3>
<p>We rewrite the log-likelihood equation stated before:</p>
<p><span class="math display">\[
\begin{align}
\ell(Y,\beta)=\log L(Y,\beta) &amp;=\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right) \\
                              &amp;=-\sum_{i=1}^{n} \ell_{logistic} \left(p_{\beta}(x_i),y_i\right) \\
                              &amp;= -n\hat{\mathrm R}(p_\beta)
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\ell_{logistic}: \{0,1\}\times \{0,1\} \to \mathbb R^+\)</span>:</p>
<p><span class="math display">\[
\ell_{logistic}(y,z) = -y\log(z)-(1-y)\log(1-z)=\left\{ \begin{array}{ll}
    -\log(z) &amp;  \mbox{if } y = 1\cr
    -\log(1-z) &amp;  \mbox{if } y = 0\cr
\end{array} \right.
\]</span></p>
<p>and <span class="math inline">\(\hat{\mathrm{R}}(p_\beta)\)</span> is the empirical risk on the training set.</p>
<p>Estimating <span class="math inline">\(\beta\)</span> by maximizing the log-likelihood is equivalent to minimizing with respect to <span class="math inline">\(\beta\)</span> the empirical risk of <span class="math inline">\(p_\beta\)</span> for the logistic loss.</p>
</section>
<section id="the-logistic-regression-model-26" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---the-r-glm-output">Interpretation - the R <code>glm()</code> output</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="fu">summary</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>Based on this output, the fitted model is (we have re-scaled balance and income for better readability):</p>
<p><span class="math display">\[
\log \bigg( \frac{p_{\beta}(x_i)}{1 - p_{\beta}(x_i)}\bigg) = -1.08 - 0.65(\mathbb{1}_{\mathrm{student}_i=\mathrm{Yes}}) + 5.74(\frac{\mathrm{balance}_i}{1000})+ 0.03(\frac{\mathrm{income}_i}{10000})
\]</span></p>
</section>
<section id="the-logistic-regression-model-27" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---logits">Interpretation - logits</h3>
<p><span class="math display">\[
\log \bigg( \frac{p_{\beta}(x_i)}{1 - p_{\beta}(x_i)}\bigg) = -1.08 - 0.65(\mathbb{1}_{\mathrm{student}_i=\mathrm{Yes}}) + 5.74(\frac{\mathrm{balance}_i}{1000})+ 0.03(\frac{\mathrm{income}_i}{10000})
\]</span></p>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Coefficients interpretation</strong></p>
</div>
<div class="callout-content">
<p>We cannot interpret the coefficients in the same manner as we interpret coefficients from a linear model, as the outcome is now expressed in “logits”:</p>
<ul>
<li>The predicted logit (or as we will see later log-odds) of defaulting for non-students with zero balance and income are <span class="math inline">\(-1.08\)</span>.</li>
<li>Each one-unit difference in <span class="math inline">\(\frac{\mathrm{balance}}{1000}\)</span> is associated with a difference of 5.74 in the predicted logit of defaulting.</li>
<li>Each one-unit difference in <span class="math inline">\(\frac{\mathrm{income}}{10000}\)</span> is associated with a difference of 0.03 in the predicted logit of defaulting.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="the-logistic-regression-model-28" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---odds">Interpretation - odds</h3>
<p>We remind the following relationship:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x))=\log(\frac{p_{\beta}(x)}{1-p_{\beta}(x)})=x^T\beta
\]</span></p>
<p>The ratio on which we take the logarithm is called <a href="https://en.wikipedia.org/wiki/Odds">odds</a>:</p>
<p><span class="math display">\[
odd_\beta(x) = \frac{p_{\beta}(x)}{1-p_{\beta}(x)}=exp(x^T\beta)
\]</span></p>
<p>It represents the chance an event occurs (<span class="math inline">\(p_{\beta}(x)\)</span>) versus the chance that same event does not occur (<span class="math inline">\(1-p_{\beta}(x)\)</span>).</p>
<p>We can also rewrite:</p>
<p><span class="math display">\[
p_\beta(x) = \frac{odds_{\beta}(x)}{1+odds_{\beta}(x)}
\]</span></p>
</section>
<section id="the-logistic-regression-model-29" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---odds-1">Interpretation - odds</h3>
<p>To set these ideas, for a variable <span class="math inline">\(x\)</span> in <span class="math inline">\([-5,5]\)</span>, we plot the logistic curve (i.e.&nbsp;the probabilities) together with the odds and the logits (ie log(odds)):</p>

<img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-16-1.png" width="960" class="r-stretch"></section>
<section id="the-logistic-regression-model-30" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---odds-ratio">Interpretation - odds ratio</h3>
<p>For two observations <span class="math inline">\(x\)</span> and <span class="math inline">\(\tilde{x}\)</span> we define odds ratio as:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\frac{odds(x)}{odds(\tilde{x})}
\]</span> Odds ratio are used to compare probabilities between two observations:</p>
<ul>
<li><span class="math inline">\(OR(x,\tilde{x}) = 1 \Leftrightarrow p(x)=p(\tilde{x})\)</span></li>
<li><span class="math inline">\(OR &gt; 1 \Leftrightarrow p(x)&gt;p(\tilde{x})\)</span></li>
<li><span class="math inline">\(OR &lt; 1 \Leftrightarrow p(x)&lt;p(\tilde{x})\)</span></li>
</ul>
<p>They are also used to measure the impact of a predictor:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\exp(\beta_1(x_1-\tilde{x_1}))\cdots exp(\beta_p(x_p-\tilde{x_p}))
\]</span></p>
<p>Choosing <span class="math inline">\((x,\tilde{x})\)</span> differing by only one predictor <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\exp(\beta_j(x_j-\tilde{x_j}))
\]</span></p>
</section>
<section id="the-logistic-regression-model-31" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="interpretation---odds-ratio-1">Interpretation - odds ratio</h3>
<p><span class="math inline">\(exp(\beta_j)\)</span> is the odds ratio associated with a one-unit increase in the <span class="math inline">\(x_j\)</span>.</p>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>Interpret the coefficients in terms of odds:</p>
<ul>
<li>The coefficient of balance / 1000 is 5.737. Hence an increase of balance by 1000 points increases odds for default by a factor of exp(5.737)=310.</li>
<li>The coefficient of income / 10000 is 0.03. Hence an increase of income by 10000 points increases odds for default by a factor of exp(0.03)=1.03.</li>
<li>The coefficient of “being a student” is -0.647. Hence being a student decreases odds for default by a factor of exp(-0.647)=0.52.</li>
</ul>
</div>
</div>
</div>
<p>More on odds ratio interpretation can be found <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/">here</a>.</p>
</section>
<section id="the-logistic-regression-model-32" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---asymptotic-properties-of-mle">Inference - asymptotic properties of MLE</h3>
<p>Under certain assumptions (see for example <span class="citation" data-cites="gourieroux1981">Gourieroux &amp; Monfort (<a href="#/references" role="doc-biblioref" onclick="">1981</a>)</span> or <span class="citation" data-cites="fahrmeir1986">Fahrmeir &amp; Kaufmann (<a href="#/references" role="doc-biblioref" onclick="">1986</a>)</span>), the Maximum Likelihood Estimator has the following asymptotic properties:</p>
<p><span class="math display">\[
\hat\beta \xrightarrow[] {p} \beta \textrm{, as n} \to \infty
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\sqrt n(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \mathcal N(0,\mathcal I(\beta)^{-1})\textrm{, as n} \to \infty
\]</span> where:</p>
<p><span class="math display">\[
\mathcal I(\beta) = -\mathbb{E}[\nabla^2\ell(Y,\beta)]=-\frac{1}{n}\nabla^2\ell(Y,\beta)=\frac{1}{n}X^T W_\beta X
\]</span></p>
<p>where <span class="math inline">\(\mathcal I(\beta)\)</span> is the Fisher information matrix. We recognize the Hessian matrix we have seen before.</p>
</section>
<section id="the-logistic-regression-model-33" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---asymptotic-properties-of-mle-1">Inference - asymptotic properties of MLE</h3>
<p>The asymptotic property rewrites:</p>
<p><span class="math display">\[
(\hat\beta-\beta)^Tn\mathcal I(\beta)(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \chi_p^2
\]</span></p>
<p>As <span class="math inline">\(\mathcal I(\beta)\)</span> is unknown we use instead <span class="math inline">\(\mathcal I(\hat\beta)=\frac{1}{n}X^T W_\hat\beta X\)</span>. Since <span class="math inline">\(\hat\beta \xrightarrow[] {p} \beta\)</span> and <span class="math inline">\(p_\beta\)</span> continuous in <span class="math inline">\(\beta\)</span> it can be shown that:</p>
<p><span class="math display">\[
(\hat\beta-\beta)^TX^T W_{\hat\beta} X(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \chi_p^2
\]</span></p>
<p>Or equivalently:</p>
<p><span class="math display">\[
\hat\beta -\beta \xrightarrow[]{\mathcal L} \mathcal N(0,\mathcal ( X^T W_{\hat\beta} X )^{-1})
\]</span></p>
</section>
<section id="the-logistic-regression-model-34" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics">Inference - Wald statistics</h3>
<p>Using the preceding asymptotic properties we can derive confidence interval and tests for the coefficients <span class="math inline">\(\beta_j\)</span>, <span class="math inline">\(j =1,\cdots,p\)</span> of the model:</p>
<p><span class="math display">\[
\frac{\hat\beta_j-\beta_j}{\hat \sigma_j} \xrightarrow[]{\mathcal L} \mathcal N(0,1)
\]</span> where <span class="math inline">\(\hat \sigma_j^2= s.e.(\hat\beta_j)^2\)</span> denotes the <span class="math inline">\(j-th\)</span> term of <span class="math inline">\(( X^T W_{\hat\beta} X )^{-1}\)</span> diagonal.</p>
<p>The typical formula for a <span class="math inline">\(1-\alpha\)</span> confidence interval is:</p>
<p><span class="math display">\[
\hat\beta_j \pm z_{1-\alpha/2} \hat \sigma_j
\]</span> where <span class="math inline">\(z_{1-\alpha/2}\)</span> is the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the standard normal distribution.</p>
</section>
<section id="the-logistic-regression-model-35" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics-1">Inference - Wald statistics</h3>
<p>Going further, the asymptotic properties of MLE also allow to test the “statistical significance” of each coefficient in the model, the Wald test.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_j=0\)</span> and <span class="math inline">\(\textrm{H}_1\textrm{: } \beta_j \neq 0\)</span> we have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
\frac{\hat\beta_j}{\hat \sigma_j} \xrightarrow[]{\mathcal L} \mathcal N(0,1)
\]</span> We will reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> if the absolute of the observed value <span class="math inline">\(\frac{\hat\beta_j}{\hat \sigma_j}\)</span> (denoted in <code>glm</code> output as <code>z value</code>) is above the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the standard normal distribution.</p>
</section>
<section id="the-logistic-regression-model-36" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics-2">Inference - Wald statistics</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>glm_bal_inc <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income,</span>
<span id="cb10-2"><a href="#cb10-2"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb10-3"><a href="#cb10-3"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="fu">summary</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ balance + income, family = "binomial", 
    data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.154e+01  4.348e-01 -26.545  &lt; 2e-16 ***
balance      5.647e-03  2.274e-04  24.836  &lt; 2e-16 ***
income       2.081e-05  4.985e-06   4.174 2.99e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1579.0  on 9997  degrees of freedom
AIC: 1585

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-37" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics-3">Inference - Wald statistics</h3>
<p>We reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(p = \mathbf P(|z|&gt;|\frac{\hat\beta_j}{\hat \sigma_j}|)&lt;\alpha\)</span>.</p>
<p><span class="math inline">\(p\)</span> is called the p-value.</p>
<p>The output of <code>glm</code> in <code>R</code> shows:</p>
<ul>
<li><p><span class="math inline">\(\hat\beta_j\)</span> as <code>Estimate</code>,</p></li>
<li><p><span class="math inline">\(\hat \sigma_j\)</span> as <code>Std. Error</code>,</p></li>
<li><p>the observed test statistic <span class="math inline">\(\frac{\hat\beta_j}{\hat \sigma_j}\)</span> as <code>z value</code>,</p></li>
<li><p>and the p-value as <code>Pr(&gt;|z|)</code></p></li>
</ul>
</section>
<section id="the-logistic-regression-model-38" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics-4">Inference - Wald statistics</h3>
<p>We obtain the <code>z value</code> <span class="math inline">\(\frac{\hat\beta_j}{\hat \sigma_j}\)</span> using estimate and its standard deviation:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>z <span class="ot">&lt;-</span> glm_bal_inc<span class="sc">$</span>coefficients[<span class="dv">3</span>] <span class="sc">/</span> (<span class="fu">summary</span>(glm_bal_inc))<span class="sc">$</span>coefficients[<span class="dv">3</span>,<span class="dv">2</span>]</span>
<span id="cb12-2"><a href="#cb12-2"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  income 
4.174178 </code></pre>
</div>
</div>
<p>and then the p-value:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(z)))<span class="sc">*</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      income 
2.990638e-05 </code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-39" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---wald-statistics-5">Inference - Wald statistics</h3>
<p>Using the hessian matrix obtained before as a side product of the Newton-Raphson algorithm, we retrieve comparable values with <code>glm</code> outputs for <span class="math inline">\(\hat \sigma_j\)</span>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>std_errors <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">solve</span>(<span class="sc">-</span><span class="fu">as.matrix</span>(sol<span class="sc">$</span>hessian))))</span>
<span id="cb16-2"><a href="#cb16-2"></a>std_errors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> (Intercept)      balance       income 
4.346349e-01 2.273110e-04 4.984579e-06 </code></pre>
</div>
</div>
<p>the <code>z values</code> and then the p-values:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>z <span class="ot">&lt;-</span> sol<span class="sc">$</span>beta <span class="sc">/</span> std_errors</span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="fu">t</span>(z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     (Intercept)  balance   income
[1,]   -26.54622 24.83714 4.173579</code></pre>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1"></a><span class="fu">t</span>((<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(z)))<span class="sc">*</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     (Intercept) balance       income
[1,]           0       0 2.998516e-05</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-40" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---confidence-intervals">Inference - confidence intervals</h3>
<p>The <code>R</code> command to get confidence interval of estimators based on Wald statistic is the following (by default <span class="math inline">\(\alpha=5\%\)</span>)</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1"></a><span class="fu">confint.default</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                    2.5 %        97.5 %
(Intercept) -1.239258e+01 -1.068836e+01
balance      5.201460e-03  6.092746e-03
income       1.103823e-05  3.057972e-05</code></pre>
</div>
</div>
<p>We can retrieve it manually using coefficient estimate and standard deviation:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1"></a>output_bal_inc <span class="ot">=</span> <span class="fu">summary</span>(glm_bal_inc)<span class="sc">$</span>coefficients</span>
<span id="cb24-2"><a href="#cb24-2"></a>bal_std_estimate <span class="ot">&lt;-</span> output_bal_inc[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb24-3"><a href="#cb24-3"></a>bal_std_error <span class="ot">&lt;-</span> output_bal_inc[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb24-4"><a href="#cb24-4"></a></span>
<span id="cb24-5"><a href="#cb24-5"></a><span class="co"># upper bound for beta(balance) at 5%</span></span>
<span id="cb24-6"><a href="#cb24-6"></a>upper <span class="ot">&lt;-</span> bal_std_estimate <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> bal_std_error</span>
<span id="cb24-7"><a href="#cb24-7"></a></span>
<span id="cb24-8"><a href="#cb24-8"></a><span class="co"># lower bound for beta(balance) at 5%</span></span>
<span id="cb24-9"><a href="#cb24-9"></a>lower <span class="ot">&lt;-</span> bal_std_estimate <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> bal_std_error</span>
<span id="cb24-10"><a href="#cb24-10"></a>(bal_confint <span class="ot">&lt;-</span> <span class="fu">c</span>(lower, upper))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.005201452 0.006092754</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-41" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---confidence-intervals-1">Inference - confidence intervals</h3>
<p>The following <code>R</code> command provides confidence interval of estimators using a more advanced profile likelihood method:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a><span class="fu">confint</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                    2.5 %        97.5 %
(Intercept) -1.241910e+01 -1.071361e+01
balance      5.214030e-03  6.105971e-03
income       1.105359e-05  3.060844e-05</code></pre>
</div>
</div>
<p>More details on profile likelihood method can be found <a href="https://stats.stackexchange.com/questions/5304/why-is-there-a-difference-between-manually-calculating-a-logistic-regression-95">here</a>.</p>
</section>
<section id="the-logistic-regression-model-42" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients">Inference - tests on model coefficients</h3>
<p>Based on the same idea, it is possible to test for the nullity of a subset of the model coefficients.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_1=\cdots=\beta_q=0\)</span>, <span class="math inline">\(\textrm{H}_1\textrm{: } \exists j \in \{1,\cdots,q \} \textrm{ }|\textrm{ }\beta_j \neq 0\)</span>, <span class="math inline">\(\hat\beta=(\hat\beta_1,\cdots,\hat\beta_p)\)</span> the MLE and <span class="math inline">\(\hat\beta_{1:q}=(\hat\beta_1,\cdots,\hat\beta_q)\)</span> the vector of first <span class="math inline">\(q\)</span> parameters.</p>
<p>We have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
\hat\beta_{1:q}^T( X^T W_{\hat\beta} X )^{-1}_{1:q}\hat\beta_{1:q} \xrightarrow[]{\mathcal L} \chi_q^2
\]</span> where <span class="math inline">\((X^T W_{\hat\beta} X )^{-1}_{1:q}\)</span> is the <span class="math inline">\(q \times q\)</span> upper left block matrix extracted from the inverse of hessian.</p>
<p>We will reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> if the observed value <span class="math inline">\(\hat\beta_{1:q}^T( X^T W_{\hat\beta} X )^{-1}_{1:q}\hat\beta_{1:q}\)</span> is above the <span class="math inline">\(1-\alpha\)</span> quantile of the <span class="math inline">\(\chi_q^2\)</span> distribution.</p>
</section>
<section id="the-logistic-regression-model-43" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients-1">Inference - tests on model coefficients</h3>
<p>We show below the Wald tests for each coefficient in the model using <code>summary</code>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1"></a><span class="fu">summary</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-44" class="slide level2 smaller scrollable">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients-2">Inference - tests on model coefficients</h3>
<p>These tests can be also performed in <code>R</code> using <code>car::Anova</code> or <code>aod::wald.test</code> routines. In particular when categorical variables have more than two levels these functions allow to test each variables as a whole (vs coefficient by coefficient when using <code>summary</code>)</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(glm_default, <span class="at">type=</span><span class="dv">3</span>, <span class="at">test.statistic=</span> <span class="st">"Wald"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table (Type III tests)

Response: default
            Df    Chisq Pr(&gt;Chisq)    
(Intercept)  1 487.5303  &lt; 2.2e-16 ***
student      1   7.4947   0.006188 ** 
balance      1 611.9470  &lt; 2.2e-16 ***
income       1   0.1368   0.711520    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-45" class="slide level2 smaller scrollable">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients-3">Inference - tests on model coefficients</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a><span class="co"># Testing the income coefficient (Terms = 4)</span></span>
<span id="cb32-2"><a href="#cb32-2"></a>aod<span class="sc">::</span><span class="fu">wald.test</span>(<span class="at">b =</span> <span class="fu">coef</span>(glm_default), <span class="at">Sigma =</span> <span class="fu">vcov</span>(glm_default), <span class="at">Terms =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Wald test:
----------

Chi-squared test:
X2 = 0.14, df = 1, P(&gt; X2) = 0.71</code></pre>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a><span class="co"># Testing the income coefficient (Terms = 4)</span></span>
<span id="cb34-2"><a href="#cb34-2"></a>aod<span class="sc">::</span><span class="fu">wald.test</span>(<span class="at">b =</span> <span class="fu">coef</span>(glm_default), <span class="at">Sigma =</span> <span class="fu">vcov</span>(glm_default), <span class="at">Terms =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Wald test:
----------

Chi-squared test:
X2 = 7.5, df = 1, P(&gt; X2) = 0.0062</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-46" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients-4">Inference - tests on model coefficients</h3>
<p>We can retrieve these outputs manually:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a>sum_default <span class="ot">&lt;-</span> <span class="fu">summary</span>(glm_default)</span>
<span id="cb36-2"><a href="#cb36-2"></a>beta_income <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">1</span>]</span>
<span id="cb36-3"><a href="#cb36-3"></a>stdev_income <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">2</span>]</span>
<span id="cb36-4"><a href="#cb36-4"></a></span>
<span id="cb36-5"><a href="#cb36-5"></a>wald <span class="ot">&lt;-</span> beta_income <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> stdev_income <span class="sc">^</span> <span class="dv">2</span></span>
<span id="cb36-6"><a href="#cb36-6"></a></span>
<span id="cb36-7"><a href="#cb36-7"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(wald, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7115203</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a>z_val <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">3</span>]</span>
<span id="cb38-2"><a href="#cb38-2"></a></span>
<span id="cb38-3"><a href="#cb38-3"></a><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(z_val)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7115203</code></pre>
</div>
</div>
<p>With all routines, the p-value for the income coefficient is <span class="math inline">\(0.71\)</span> validating the null hypothesis.</p>
</section>
<section id="the-logistic-regression-model-47" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="inference---tests-on-model-coefficients-5">Inference - tests on model coefficients</h3>
<p>Using <code>Terms</code> or <code>L</code> parameters in <code>aod::wald.test</code> it is also feasible to test the null hypothesis for a subsets of parameters:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a><span class="co"># Testing the income coefficient (Terms = 4)</span></span>
<span id="cb40-2"><a href="#cb40-2"></a>aod<span class="sc">::</span><span class="fu">wald.test</span>(<span class="at">b =</span> <span class="fu">coef</span>(glm_default), <span class="at">Sigma =</span> <span class="fu">vcov</span>(glm_default), <span class="at">Terms =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Wald test:
----------

Chi-squared test:
X2 = 698.3, df = 3, P(&gt; X2) = 0.0</code></pre>
</div>
</div>
<p>The null hypothesis is rejected for the model with balance and student.</p>
</section>
<section id="the-logistic-regression-model-48" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests">Likelihood ratio tests</h3>
<p>It is possible to test for the nullity of a subset of the model coefficients using Likelihood Ratio statistics.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_1=\cdots=\beta_q=0\)</span>, <span class="math inline">\(\textrm{H}_1\textrm{: } \exists j \in \{1,\cdots,q \} \textrm{ }|\textrm{ }\beta_j \neq 0\)</span>, and <span class="math inline">\(\hat\beta=(\hat\beta_1,\cdots,\hat\beta_p)\)</span> the MLE, we have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
-2\left(\ell_{\textrm{H}_0}(Y,\hat\beta_{\textrm{H}_0})-\ell(Y,\hat\beta)\right)\xrightarrow[]{\mathcal L} \chi_q^2
\]</span> where <span class="math inline">\(\ell_{\textrm{H}_0}(Y,\hat\beta_{\textrm{H}_0})\)</span> is the log-likelihood of:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(X))=x_{q+1}\beta_{q+1}+\cdots+x_{n}\beta_{n}
\]</span></p>
</section>
<section id="the-logistic-regression-model-49" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests-1">Likelihood ratio tests</h3>
<p>Consider two models, a larger model with <span class="math inline">\(l\)</span> parameters and likelihood <span class="math inline">\(L_L\)</span> and a smaller model with <span class="math inline">\(s\)</span> parameters and likelihood <span class="math inline">\(L_S\)</span>, where the smaller model represents a subset of the larger model. Typically the smaller model is equivalent to the large model where we have imposed:</p>
<p><span class="math display">\[
\textrm{H}_0\textrm{: } \ \beta_j = \ldots  = \beta_{j+r}  = 0
\]</span> Likelihood Ratio tests on variables may be performed in <code>R</code> using <code>car::Anova</code>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(glm_default, <span class="at">type=</span><span class="dv">3</span>, <span class="at">test.statistic=</span> <span class="st">"LR"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table (Type III tests)

Response: default
        LR Chisq Df Pr(&gt;Chisq)    
student     7.42  1   0.006445 ** 
balance  1335.95  1  &lt; 2.2e-16 ***
income      0.14  1   0.711514    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-50" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests-2">Likelihood ratio tests</h3>
<p>Using base <code>R</code> <code>anova</code> it is also possible to test subsets of variables and in particular individual variables within the “full” model, we have to fit <code>glm</code> for each sub model:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1"></a>glm_wo_student <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income,</span>
<span id="cb44-2"><a href="#cb44-2"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb44-3"><a href="#cb44-3"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb44-4"><a href="#cb44-4"></a>glm_wo_balance <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> student <span class="sc">+</span> income,</span>
<span id="cb44-5"><a href="#cb44-5"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb44-6"><a href="#cb44-6"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb44-7"><a href="#cb44-7"></a>glm_wo_income <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> student <span class="sc">+</span> balance,</span>
<span id="cb44-8"><a href="#cb44-8"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb44-9"><a href="#cb44-9"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="the-logistic-regression-model-51" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests-3">Likelihood ratio tests</h3>
<p>Testing the model without student predictor:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a><span class="fu">anova</span>(glm_wo_student, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: default ~ balance + income
Model 2: default ~ student + balance + income
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   
1      9997     1579.0                        
2      9996     1571.5  1   7.4214 0.006445 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>We can retrieve this result manually:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a>LRT <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(glm_default)<span class="sc">-</span><span class="fu">logLik</span>(glm_wo_student))</span>
<span id="cb47-2"><a href="#cb47-2"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(LRT, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' 0.006445112 (df=4)</code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-52" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests-4">Likelihood ratio tests</h3>
<p>Testing the other sub models:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1"></a><span class="fu">anova</span>(glm_wo_balance, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: default ~ student + income
Model 2: default ~ student + balance + income
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1      9997     2907.5                          
2      9996     1571.5  1     1336 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1"></a><span class="fu">anova</span>(glm_wo_income, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: default ~ student + balance
Model 2: default ~ student + balance + income
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
1      9997     1571.7                     
2      9996     1571.5  1  0.13677   0.7115</code></pre>
</div>
</div>
<p>The deviance defined as <span class="math inline">\(D=-2 \ell\)</span> is often reported by statistical software in place of log-likelihood. A large likelihood corresponding to a small deviance.</p>
</section>
<section id="the-logistic-regression-model-53" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="likelihood-ratio-tests-5">Likelihood ratio tests</h3>
<p>A better and full coverage of tests in the context of Logistic Regression can be found <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/">here</a> or in <span class="citation" data-cites="hosmer2013">(<a href="#/references" role="doc-biblioref" onclick="">Hosmer et al., 2013</a>)</span>. See also <a href="https://stats.oarc.ucla.edu/r/dae/logit-regression/">here</a> for a data analysis using <code>R</code> and see the question <a href="https://stats.stackexchange.com/questions/86351/interpretation-of-rs-output-for-binomial-regression">here</a> for a very detailed description of the outputs of <code>glm()</code> (in particular this <a href="https://stats.stackexchange.com/a/86375">answer</a>).</p>
</section>
<section id="the-logistic-regression-model-54" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration">Goodness of Fit test / Calibration</h3>
<p>Although it is generally not recommended by practitioners and theoreticians, the Hosmer &amp; Lemeshow test (see <a href="https://en.wikipedia.org/wiki/Hosmer–Lemeshow_test">here</a>, <a href="https://stats.stackexchange.com/questions/169438/evaluating-logistic-regression-and-interpretation-of-hosmer-lemeshow-goodness-of">here</a> or <a href="https://stats.stackexchange.com/a/18772">here</a>) allows to quickly assess the “goodness of fit” of a Logistic Regression.</p>
<p>But more than the test in itself, the underlying motivation is interesting: the Logistic Regression model provides an estimate of the probability of an outcome (success/failure, here the default is success or 1). The estimated probability of this outcome should be close to the true observed probability.</p>
<p>The Hosmer &amp; Lemeshow test assess if observed event rates match expected event rates in subgroups of “similar” observations. Models for which expected and observed event rates agree on these subgroups are considered well calibrated.</p>
</section>
<section id="the-logistic-regression-model-55" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-1">Goodness of Fit test / Calibration</h3>
<p>A first step of the test is to order the predicted probabilities of the outcome and divide it into Q groups (usually using deciles, Q=10). Then the average predicted probability for each group is computed and compared to the observed probability.</p>
<p>The Hosmer &amp; Lemeshow test statistic <span class="math inline">\(H\)</span> is compared to a <span class="math inline">\(\chi_{Q-2}^2\)</span> distribution:</p>
<p><span class="math display">\[H=\sum_{q=1}^{Q}\frac{(o_{q}-m_{q}\mu_{q})^2}{m_{q}\mu_{q}(1-\mu_{q})} \]</span> where:</p>
<ul>
<li><span class="math inline">\(o_q\)</span> denotes the number of success (<span class="math inline">\(Y=1\)</span>) observed in group <span class="math inline">\(q\)</span>,</li>
<li><span class="math inline">\(\mu_q\)</span> denotes the mean of <span class="math inline">\(p_{\hat\beta}(x_i)\)</span> in group <span class="math inline">\(q\)</span>,</li>
<li><span class="math inline">\(m_q\)</span> denotes the number of observations in group <span class="math inline">\(q\)</span>, so that <span class="math inline">\(m_{q}\mu_{q}\)</span> is the expected number of success in group <span class="math inline">\(q\)</span>.</li>
</ul>
<p>The null hypothesis is that observed/expected outcomes are close along all subgroups.</p>
</section>
<section id="the-logistic-regression-model-56" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-2">Goodness of Fit test / Calibration</h3>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1"></a><span class="fu">library</span>(glmtoolbox)</span>
<span id="cb53-2"><a href="#cb53-2"></a><span class="fu">hltest</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
   The Hosmer-Lemeshow goodness-of-fit test

 Group Size Observed     Expected
     1 1000        0   0.02653992
     2 1000        0   0.10737240
     3 1000        0   0.29143249
     4 1000        1   0.67265778
     5 1000        2   1.39515666
     6 1000        1   2.87108745
     7 1000        7   5.98948667
     8 1000       16  13.74542953
     9 1000       45  39.52811751
    10 1000      261 268.37271994

         Statistic =  3.68229 
degrees of freedom =  8 
           p-value =  0.88459 </code></pre>
</div>
</div>
<p>Here the p-value for a chi-squared statistic of <span class="math inline">\(H=3.68\)</span> with <span class="math inline">\(df=Q-2=8\)</span> is <span class="math inline">\(p=0.885\)</span> which is well above the usual levels (eg <span class="math inline">\(0.05\)</span>), so that the null hypothesis is accepted, goodness of fit is acceptable.</p>
<p>However the Hosmer &amp; Lemeshow test is dependent on the choice of Q and the binning performed on probabilities and is sometimes considered unreliable.</p>
</section>
<section id="the-logistic-regression-model-57" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-3">Goodness of Fit test / Calibration</h3>
<p>Nonetheless it is usual to assess or diagnose the good calibration of a model probabilities using Calibration Plots or Probability Calibration Curves (see here for a <a href="https://www.tidyverse.org/blog/2022/11/model-calibration/">recent R package from the tidyverse/tidymodel ecosystem</a> and here for a <a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html">scikit-learn version</a>): they are used to visualize if predictions are consistent with the observed event rates (be it on the training set or a testing set, which is better).</p>
</section>
<section id="the-logistic-regression-model-58" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-4">Goodness of Fit test / Calibration</h3>
<p>For example considering the <code>default</code> data set we have:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a>check_default_prob <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">cbind</span>(<span class="at">fitted=</span>glm_default<span class="sc">$</span>fitted.values,</span>
<span id="cb55-2"><a href="#cb55-2"></a>                                      <span class="at">Y =</span> default_data <span class="sc">%&gt;%</span></span>
<span id="cb55-3"><a href="#cb55-3"></a>                                        <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb55-4"><a href="#cb55-4"></a>                                        <span class="fu">pull</span>(default)))</span>
<span id="cb55-5"><a href="#cb55-5"></a>(calibration_data <span class="ot">&lt;-</span> check_default_prob <span class="sc">%&gt;%</span></span>
<span id="cb55-6"><a href="#cb55-6"></a>  <span class="fu">mutate</span>(<span class="at">bins_prob =</span> <span class="fu">cut</span>(fitted, <span class="at">breaks =</span> <span class="fu">quantile</span>(fitted,<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.10</span>)), <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb55-7"><a href="#cb55-7"></a>  <span class="fu">group_by</span>(bins_prob) <span class="sc">%&gt;%</span></span>
<span id="cb55-8"><a href="#cb55-8"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb55-9"><a href="#cb55-9"></a>            <span class="at">def =</span> <span class="fu">sum</span>(Y),</span>
<span id="cb55-10"><a href="#cb55-10"></a>            <span class="at">no_def =</span> n <span class="sc">-</span> def,  </span>
<span id="cb55-11"><a href="#cb55-11"></a>            <span class="at">predict_prob =</span> <span class="fu">mean</span>(fitted),</span>
<span id="cb55-12"><a href="#cb55-12"></a>            <span class="at">real_prob =</span> def<span class="sc">/</span>n,</span>
<span id="cb55-13"><a href="#cb55-13"></a>            <span class="at">forecast_acc =</span> def <span class="sc">/</span> <span class="fu">sum</span>(check_default_prob<span class="sc">$</span>Y)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 10 × 7
   bins_prob               n   def no_def predict_prob real_prob forecast_acc
   &lt;fct&gt;               &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;
 1 [1.03e-05,5.14e-05]  1000     0   1000    0.0000265     0          0      
 2 (5.14e-05,0.000176]  1000     0   1000    0.000107      0          0      
 3 (0.000176,0.000443]  1000     0   1000    0.000291      0          0      
 4 (0.000443,0.000945]  1000     1    999    0.000673      0.001      0.00300
 5 (0.000945,0.00197]   1000     2    998    0.00140       0.002      0.00601
 6 (0.00197,0.00402]    1000     1    999    0.00287       0.001      0.00300
 7 (0.00402,0.0088]     1000     7    993    0.00599       0.007      0.0210 
 8 (0.0088,0.021]       1000    16    984    0.0137        0.016      0.0480 
 9 (0.021,0.0709]       1000    45    955    0.0395        0.045      0.135  
10 (0.0709,0.978]       1000   261    739    0.268         0.261      0.784  </code></pre>
</div>
</div>
</section>
<section id="the-logistic-regression-model-59" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-5">Goodness of Fit test / Calibration</h3>
<div class="cell">
<div class="cell-output-display">
<p><img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-40-1.png" width="960"></p>
</div>
<div class="cell-output-display">
<p><img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-40-2.png" width="960"></p>
</div>
</div>
</section>
<section id="the-logistic-regression-model-60" class="slide level2 smaller">
<h2>The Logistic Regression model</h2>
<h3 id="goodness-of-fit-test-calibration-6">Goodness of Fit test / Calibration</h3>

<img data-src="2_logreg_files/figure-revealjs/unnamed-chunk-41-1.png" width="960" class="r-stretch"><p>The model tends to slightly overestimate/underestimates some deciles without a clear pattern.</p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-albert1984a" class="csl-entry" role="listitem">
Albert, A., &amp; Aanderson, J. A. (1984). On the existence of maximum likelihood estimates in logistic regression models. <em>Biometrika</em>, <em>71</em>(1), 1–10. <a href="https://doi.org/10.1093/biomet/71.1.1">https://doi.org/10.1093/biomet/71.1.1</a>
</div>
<div id="ref-fahrmeir1986" class="csl-entry" role="listitem">
Fahrmeir, L., &amp; Kaufmann, H. &amp;. (1986). Asymptotic inference in discrete response models. <em>Statistische Hefte</em>, <em>27</em>(1), 179–205. <a href="https://doi.org/10.1007/bf02932567">https://doi.org/10.1007/bf02932567</a>
</div>
<div id="ref-gourieroux1981" class="csl-entry" role="listitem">
Gourieroux, C., &amp; Monfort, A. (1981). Asymptotic properties of the maximum likelihood estimator in dichotomous logit models. <em>Journal of Econometrics</em>, <em>17</em>(1), 83–97. <a href="https://doi.org/10.1016/0304-4076(81)90060-9">https://doi.org/10.1016/0304-4076(81)90060-9</a>
</div>
<div id="ref-hosmer2013" class="csl-entry" role="listitem">
Hosmer, D. W., Lemeshow, S., &amp; Sturdivant, R. X. (2013). Applied logistic regression. In <em>Wiley Series in Probability and Statistics</em>.
</div>
<div id="ref-islr2021" class="csl-entry" role="listitem">
James, G., Witten, D., Hastie, T., &amp; Tibshirani, R. (2021). <em>An introduction to statistical learning: With applications in r</em>. Springer US. <a href="https://doi.org/10.1007/978-1-0716-1418">https://doi.org/10.1007/978-1-0716-1418</a>
</div>
</div>
<div class="footer footer-default">

</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="2_logreg_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="2_logreg_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="2_logreg_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="2_logreg_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>